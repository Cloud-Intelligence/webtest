---
import Layout from '../../layouts/Layout.astro';
import PageHero from '../../components/PageHero.astro';

const features = [
  {
    title: "Data Pipelines",
    description: "Build robust, scalable data pipelines that efficiently process and transform data from multiple sources with automated workflows.",
    icon: "üîÑ"
  },
  {
    title: "ETL/ELT Processing",
    description: "Design and implement extraction, transformation, and loading processes to move data between systems with high reliability.",
    icon: "‚öôÔ∏è"
  },
  {
    title: "Real-time Streaming",
    description: "Process continuous data streams in real-time with technologies like Apache Kafka, Apache Flink, and cloud-native solutions.",
    icon: "üåä"
  },
  {
    title: "Data Lakes",
    description: "Architect and implement data lakes that store structured and unstructured data at scale with cost-effective storage solutions.",
    icon: "üèûÔ∏è"
  },
  {
    title: "Data Warehousing",
    description: "Build modern data warehouses optimized for analytics with dimensional modeling and columnar storage architectures.",
    icon: "üèóÔ∏è"
  },
  {
    title: "Data Quality Management",
    description: "Implement comprehensive data quality frameworks with validation, monitoring, and automated remediation processes.",
    icon: "‚úÖ"
  }
];
---

<Layout 
  title="Data Engineering - Cloud Intelligence"
  description="Build scalable data infrastructure and pipelines that transform raw data into valuable business insights."
  keywords="data engineering, data pipelines, ETL, data lakes, data warehousing, real-time streaming"
>
  <PageHero 
    title="Data Engineering"
    subtitle="Scalable Data Infrastructure"
    description="Transform your data landscape with robust pipelines, modern architectures, and real-time processing capabilities."
  />
  
  <section class="content-section">
    <div class="container">
      <div class="intro-content">
        <h2>Unlock the Power of Your Data</h2>
        <p>
          Our data engineering solutions help organizations build reliable, scalable data infrastructure 
          that supports analytics, machine learning, and business intelligence initiatives. From real-time 
          streaming to batch processing, we create data systems that grow with your business needs.
        </p>
      </div>
      
      <div class="features-grid">
        {features.map((feature) => (
          <div class="feature-card">
            <div class="feature-icon">{feature.icon}</div>
            <h3>{feature.title}</h3>
            <p>{feature.description}</p>
          </div>
        ))}
      </div>
      
      <div class="cta-section">
        <h2>Ready to Transform Your Data Architecture?</h2>
        <p>Build the foundation for data-driven decision making</p>
        <a href="#contact" class="cta-button">Get Started</a>
      </div>
    </div>
  </section>
  
  <!-- FAQ Section -->
  <section class="faq-section">
    <div class="container">
      <h2>Frequently Asked Questions</h2>
      <div class="faq-grid">
        <div class="faq-item">
          <h3>What data sources can you integrate?</h3>
          <p>We integrate with databases (SQL, NoSQL), APIs, file systems, cloud storage, streaming platforms (Kafka, Kinesis), SaaS applications, IoT devices, and legacy systems. Our pipelines handle structured, semi-structured, and unstructured data from any source with appropriate connectors and protocols.</p>
        </div>
        <div class="faq-item">
          <h3>How do you ensure data quality and reliability?</h3>
          <p>We implement comprehensive data quality frameworks including schema validation, data profiling, anomaly detection, automated testing, lineage tracking, and monitoring dashboards. Our pipelines include error handling, data reconciliation, and automated alerts for quality issues.</p>
        </div>
        <div class="faq-item">
          <h3>Can you handle both real-time and batch processing?</h3>
          <p>Yes, we design hybrid architectures supporting both real-time streaming and batch processing. We use technologies like Apache Kafka, Flink, Spark, and cloud-native services to process data at different velocities based on business requirements and latency needs.</p>
        </div>
        <div class="faq-item">
          <h3>What cloud platforms do you work with?</h3>
          <p>We work with all major cloud platforms including AWS (S3, Redshift, Glue, Kinesis), Google Cloud (BigQuery, Dataflow, Pub/Sub), Azure (Data Factory, Synapse, Event Hubs), and hybrid multi-cloud architectures. We select platforms based on your existing infrastructure and requirements.</p>
        </div>
        <div class="faq-item">
          <h3>How do you handle data security and compliance?</h3>
          <p>We implement encryption in transit and at rest, access controls, data masking, audit logging, and compliance frameworks (GDPR, HIPAA, SOC 2). Our pipelines include data lineage tracking, retention policies, and automated compliance reporting for regulatory requirements.</p>
        </div>
        <div class="faq-item">
          <h3>What's the typical timeline for data engineering projects?</h3>
          <p>Simple pipelines take 2-4 weeks, complex data lakes require 8-16 weeks, and enterprise-scale data platforms need 3-6 months. Timeline depends on data complexity, integration requirements, compliance needs, and performance specifications. We provide detailed project plans with milestones.</p>
        </div>
      </div>
    </div>
  </section>

</Layout>

<!-- Service Schema for Data Engineering -->
<script type="application/ld+json" is:inline>
{
  "@context": "https://schema.org",
  "@type": "Service",
  "name": "Data Engineering Solutions",
  "description": "Transform your data landscape with robust pipelines, modern architectures, and real-time processing capabilities including data lakes, warehousing, and ETL/ELT processing.",
  "provider": {
    "@type": "Organization",
    "@name": "Cloud Intelligence",
    "url": "https://cloud-intelligence.github.io/webtest/"
  },
  "areaServed": "Global",
  "availableChannel": {
    "@type": "ServiceChannel",
    "serviceUrl": "https://cloud-intelligence.github.io/webtest/solutions/data-engineering",
    "serviceType": "Data Engineering"
  },
  "category": "Software Development",
  "serviceType": "Data Engineering",
  "offers": {
    "@type": "Offer",
    "description": "Custom data engineering and infrastructure development services",
    "availability": "InStock"
  },
  "hasOfferCatalog": {
    "@type": "OfferCatalog",
    "name": "Data Engineering Services",
    "itemListElement": [
      {
        "@type": "Offer",
        "itemOffered": {
          "@type": "Service",
          "name": "Data Pipelines",
          "description": "Build robust, scalable data pipelines that efficiently process and transform data from multiple sources with automated workflows"
        }
      },
      {
        "@type": "Offer",
        "itemOffered": {
          "@type": "Service",
          "name": "ETL/ELT Processing",
          "description": "Design and implement extraction, transformation, and loading processes to move data between systems with high reliability"
        }
      },
      {
        "@type": "Offer",
        "itemOffered": {
          "@type": "Service",
          "name": "Real-time Streaming",
          "description": "Process continuous data streams in real-time with technologies like Apache Kafka, Apache Flink, and cloud-native solutions"
        }
      },
      {
        "@type": "Offer",
        "itemOffered": {
          "@type": "Service",
          "name": "Data Lakes",
          "description": "Architect and implement data lakes that store structured and unstructured data at scale with cost-effective storage solutions"
        }
      },
      {
        "@type": "Offer",
        "itemOffered": {
          "@type": "Service",
          "name": "Data Warehousing",
          "description": "Build modern data warehouses optimized for analytics with dimensional modeling and columnar storage architectures"
        }
      }
    ]
  }
}
</script>

<!-- FAQ Schema for Data Engineering -->
<script type="application/ld+json" is:inline>
{
  "@context": "https://schema.org",
  "@type": "FAQPage",
  "mainEntity": [
    {
      "@type": "Question",
      "name": "What data sources can you integrate?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "We integrate with databases (SQL, NoSQL), APIs, file systems, cloud storage, streaming platforms (Kafka, Kinesis), SaaS applications, IoT devices, and legacy systems. Our pipelines handle structured, semi-structured, and unstructured data from any source with appropriate connectors and protocols."
      }
    },
    {
      "@type": "Question",
      "name": "How do you ensure data quality and reliability?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "We implement comprehensive data quality frameworks including schema validation, data profiling, anomaly detection, automated testing, lineage tracking, and monitoring dashboards. Our pipelines include error handling, data reconciliation, and automated alerts for quality issues."
      }
    },
    {
      "@type": "Question",
      "name": "Can you handle both real-time and batch processing?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "Yes, we design hybrid architectures supporting both real-time streaming and batch processing. We use technologies like Apache Kafka, Flink, Spark, and cloud-native services to process data at different velocities based on business requirements and latency needs."
      }
    },
    {
      "@type": "Question",
      "name": "What cloud platforms do you work with?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "We work with all major cloud platforms including AWS (S3, Redshift, Glue, Kinesis), Google Cloud (BigQuery, Dataflow, Pub/Sub), Azure (Data Factory, Synapse, Event Hubs), and hybrid multi-cloud architectures. We select platforms based on your existing infrastructure and requirements."
      }
    },
    {
      "@type": "Question",
      "name": "How do you handle data security and compliance?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "We implement encryption in transit and at rest, access controls, data masking, audit logging, and compliance frameworks (GDPR, HIPAA, SOC 2). Our pipelines include data lineage tracking, retention policies, and automated compliance reporting for regulatory requirements."
      }
    },
    {
      "@type": "Question",
      "name": "What's the typical timeline for data engineering projects?",
      "acceptedAnswer": {
        "@type": "Answer",
        "text": "Simple pipelines take 2-4 weeks, complex data lakes require 8-16 weeks, and enterprise-scale data platforms need 3-6 months. Timeline depends on data complexity, integration requirements, compliance needs, and performance specifications. We provide detailed project plans with milestones."
      }
    }
  ]
}
</script>

<style lang="scss">
  .content-section {
    background: #040913;
    padding: 80px 0;
    
    @media (max-width: 768px) {
      padding: 60px 0;
    }
  }
  
  .container {
    max-width: 1200px;
    margin: 0 auto;
    padding: 0 40px;
    
    @media (max-width: 768px) {
      padding: 0 24px;
    }
  }
  
  .intro-content {
    text-align: center;
    max-width: 800px;
    margin: 0 auto 80px;
    
    h2 {
      font-family: 'Manrope', sans-serif;
      font-weight: 600;
      font-size: clamp(2rem, 4vw, 2.5rem);
      color: #FFFFFF;
      margin-bottom: 24px;
    }
    
    p {
      font-family: 'Inter', sans-serif;
      font-size: 1.125rem;
      line-height: 1.6;
      color: rgba(255, 255, 255, 0.8);
    }
  }
  
  .features-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
    gap: 32px;
    margin-bottom: 80px;
    
    @media (max-width: 768px) {
      grid-template-columns: 1fr;
      gap: 24px;
    }
  }
  
  .feature-card {
    background: rgba(255, 255, 255, 0.05);
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255, 255, 255, 0.1);
    border-radius: 16px;
    padding: 32px;
    transition: all 0.3s ease;
    
    &:hover {
      background: rgba(255, 255, 255, 0.08);
      border-color: rgba(255, 255, 255, 0.2);
      transform: translateY(-4px);
      box-shadow: 0 8px 32px rgba(0, 0, 0, 0.2);
    }
    
    .feature-icon {
      font-size: 3rem;
      margin-bottom: 16px;
    }
    
    h3 {
      font-family: 'Inter', sans-serif;
      font-weight: 600;
      font-size: 1.25rem;
      color: #FFFFFF;
      margin-bottom: 12px;
    }
    
    p {
      font-family: 'Inter', sans-serif;
      font-size: 0.975rem;
      line-height: 1.6;
      color: rgba(255, 255, 255, 0.7);
    }
  }
  
  .cta-section {
    text-align: center;
    padding: 60px;
    background: rgba(51, 102, 255, 0.1);
    backdrop-filter: blur(10px);
    border: 1px solid rgba(51, 102, 255, 0.2);
    border-radius: 24px;
    
    h2 {
      font-family: 'Manrope', sans-serif;
      font-weight: 600;
      font-size: clamp(1.75rem, 3vw, 2.25rem);
      color: #FFFFFF;
      margin-bottom: 16px;
    }
    
    p {
      font-family: 'Inter', sans-serif;
      font-size: 1.125rem;
      color: rgba(255, 255, 255, 0.8);
      margin-bottom: 32px;
    }
    
    .cta-button {
      display: inline-block;
      padding: 14px 32px;
      background: #3366FF;
      color: white;
      text-decoration: none;
      border-radius: 12px;
      font-family: 'Inter', sans-serif;
      font-weight: 500;
      font-size: 1rem;
      transition: all 0.3s ease;
      box-shadow: 0 4px 16px rgba(51, 102, 255, 0.3);
      
      &:hover {
        background: #2952CC;
        transform: translateY(-2px);
        box-shadow: 0 6px 24px rgba(51, 102, 255, 0.4);
      }
    }
  }

  // FAQ Section
  .faq-section {
    background: #FFFFFF;
    padding: 80px 0;
    
    .container {
      max-width: 1000px;
      margin: 0 auto;
      padding: 0 20px;
    }
    
    h2 {
      font-family: 'Manrope', sans-serif;
      font-size: 2.5rem;
      font-weight: 600;
      text-align: center;
      margin-bottom: 60px;
      color: #1a1a1a;
    }
    
    .faq-grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 40px;
      
      @media (max-width: 768px) {
        grid-template-columns: 1fr;
        gap: 30px;
      }
    }
    
    .faq-item {
      background: #f8f9fa;
      padding: 30px;
      border-radius: 12px;
      border-left: 4px solid #3366FF;
      
      h3 {
        font-family: 'Manrope', sans-serif;
        font-size: 1.25rem;
        font-weight: 600;
        color: #3366FF;
        margin-bottom: 16px;
        line-height: 1.4;
      }
      
      p {
        font-size: 1rem;
        line-height: 1.6;
        color: #4a4a4a;
        margin: 0;
      }
    }
  }
</style>